-- ============================================================
-- SUPABASE RAG SCHEMA (Postgres)
-- Multi-tenant via auth.users (uuid)
-- - Profiles: optionale App-Userdaten + OpenAI Key (Challenge)
-- - Documents: Upload-Metadaten + Ingestion-Status + optional raw_text
-- - Document Chunks: Embeddings für Retrieval
-- - Chat Sessions + Messages: Chat-Historie (User + Assistant)
-- - RLS Policies: Zugriff nur auf eigene Daten
-- - match_chunks(): serverseitige Similarity Search (optional, aber praktisch)
--
-- Hinweise:
-- - Für echte Prod: OpenAI Keys NICHT in DB speichern, sondern Vault/Secrets.
-- - ivfflat Index braucht ANALYZE nach größeren Inserts und ist tuning-sensitiv.
-- - PDF/Dateitypen sind vorbereitet (document_type + storage_path + status).
-- ============================================================


-- ============================================================
-- 0) EXTENSIONS
-- ============================================================

-- pgvector für Embeddings
create extension if not exists vector;

-- (Optional) Für case-insensitive username/email etc.
-- create extension if not exists citext;


-- ============================================================
-- 1) ENUMS / DOMAINS
-- ============================================================

-- Status der Dokument-Verarbeitung
do $$
begin
  if not exists (select 1 from pg_type where typname = 'document_ingestion_status') then
    create type public.document_ingestion_status as enum (
      'pending',     -- Datei vorhanden, noch nicht verarbeitet
      'processing',  -- optionaler Zwischenstatus
      'processed',   -- Text extrahiert, Chunks erzeugt
      'failed'       -- Parsing/Chunking/Embedding fehlgeschlagen
    );
  end if;
end $$;

-- (Optional) Quelle eines Dokuments
do $$
begin
  if not exists (select 1 from pg_type where typname = 'document_source') then
    create type public.document_source as enum (
      'upload',      -- Datei wurde hochgeladen (Storage)
      'paste',       -- Text wurde direkt eingefügt
      'url'          -- später: URL-Crawl/Fetch
    );
  end if;
end $$;


-- ============================================================
-- 2) PROFILES
-- ============================================================
-- Erweiterung von auth.users (Supabase Auth ist Source of Truth)
-- id = auth.users.id (uuid)

create table if not exists public.profiles (
  id uuid primary key references auth.users(id) on delete cascade,

  -- optionale Personalisierung in deiner App
  firstname varchar(100),
  lastname varchar(100),

  -- User-spezifischer OpenAI API Key (für Challenge ok)
  -- In echter Prod: Vault/Secrets, nicht als Klartext in DB.
  openai_api_key text,

  -- System Prompt fuer den Chat (wird um KONTEXT ergaenzt)
  system_prompt text default $$Du bist ein RAG-Assistent.
Nutze ausschliesslich den bereitgestellten KONTEXT um zu antworten.
Wenn der Kontext nicht ausreicht, sage klar: 'Nicht in der Wissensbasis'.
Gib am Ende eine Quellenliste im Format [1], [2], ... passend zu den verwendeten Textstellen.$$,

  created_at timestamptz not null default now(),
  updated_at timestamptz not null default now()
);

comment on table public.profiles is
'App-spezifische Profildaten je auth.users User. Optional; Auth ist Source of Truth.';

comment on column public.profiles.openai_api_key is
'Challenge-only: user-spezifischer OpenAI Key. In Prod: Secrets/Vault verwenden.';

comment on column public.profiles.system_prompt is
'System-Prompt fuer den Chat. Der KONTEXT-Block wird im Backend angehaengt.';

-- updated_at automatisch pflegen (optional, aber sauber)
create or replace function public.set_updated_at()
returns trigger
language plpgsql
as $$
begin
  new.updated_at = now();
  return new;
end;
$$;

drop trigger if exists trg_profiles_set_updated_at on public.profiles;
create trigger trg_profiles_set_updated_at
before update on public.profiles
for each row execute function public.set_updated_at();


-- ============================================================
-- 3) DOCUMENTS
-- ============================================================
-- Dokument-Metadaten + optional extrahierter Text + Ingestion Status
-- Vorbereitung für PDF/Office/etc via storage + status + error_message

create table if not exists public.documents (
  id bigint generated by default as identity primary key,

  -- Besitzer
  owner_id uuid not null references auth.users(id) on delete cascade,

  -- Anzeigename
  document_name varchar(255) not null,

  -- Quelle des Dokuments (upload/paste/url)
  source public.document_source not null default 'upload',

  -- Typ/MIME/Format (z.B. 'pdf', 'text', 'markdown', 'docx')
  -- Du kannst hier frei Strings nutzen oder später in Enum überführen.
  document_type text not null default 'text',

  -- Pfad in Supabase Storage (z.B. "documents/<uid>/<docid>.pdf")
  -- Bei 'paste' kann das NULL sein.
  storage_path varchar(1024),

  -- Aktiv-Flag (Soft Disable)
  active boolean not null default true,

  -- Extrahierter Volltext (optional; kann groß werden)
  raw_text text,

  -- Status der Verarbeitung
  ingestion_status public.document_ingestion_status not null default 'pending',

  -- Fehlerdetails, falls failed
  ingestion_error text,

  created_at timestamptz not null default now(),
  updated_at timestamptz not null default now()
);

create index if not exists documents_owner_id_idx on public.documents(owner_id);
create index if not exists documents_status_idx on public.documents(owner_id, ingestion_status);

comment on table public.documents is
'Dokumente pro User. Enthält Storage-Referenz, Typ, Ingestion-Status, optional raw_text.';

comment on column public.documents.storage_path is
'Pfad in Supabase Storage. Bei paste/url ggf. NULL.';

comment on column public.documents.ingestion_status is
'pending/processing/processed/failed: Pipeline-Status für Parsing/Chunking/Embeddings.';

drop trigger if exists trg_documents_set_updated_at on public.documents;
create trigger trg_documents_set_updated_at
before update on public.documents
for each row execute function public.set_updated_at();


-- ============================================================
-- 4) DOCUMENT_CHUNKS
-- ============================================================
-- Chunks sind die Retrieval-Einheiten.
-- embedding: vector(1536) für text-embedding-3-small
-- owner_id redundant für RLS/Performance (bewusst)

create table if not exists public.document_chunks (
  id bigint generated by default as identity primary key,

  -- Besitzer (redundant; schnellere RLS-Filter & joins)
  owner_id uuid not null references auth.users(id) on delete cascade,

  -- Ursprungsdokument
  document_id bigint not null references public.documents(id) on delete cascade,

  -- Reihenfolge im Dokument (optional, aber hilfreich)
  chunk_index int not null,

  -- Chunk-Text
  content text not null,

  -- Embedding
  embedding vector(1536) not null,

  created_at timestamptz not null default now(),

  -- Du willst pro Dokument keine doppelten Indizes
  constraint document_chunks_unique_idx_per_doc unique (document_id, chunk_index)
);

create index if not exists document_chunks_owner_id_idx on public.document_chunks(owner_id);
create index if not exists document_chunks_document_id_idx on public.document_chunks(document_id);

-- Vektorindex (Cosine) für Similarity Search
-- Hinweis: ivfflat braucht ausreichend Daten, sonst bringt es wenig.
-- Nach Bulk-Inserts: analyze public.document_chunks;
create index if not exists document_chunks_embedding_idx
on public.document_chunks
using ivfflat (embedding vector_cosine_ops)
with (lists = 100);

comment on table public.document_chunks is
'Semantische Chunks pro Dokument. Enthält content + embedding für RAG Retrieval.';

comment on column public.document_chunks.chunk_index is
'Position/Sequenz im Dokument. Unterstützt deterministische Rekonstruktion/Re-ranking.';


-- ============================================================
-- 5) CHAT_SESSIONS
-- ============================================================

create table if not exists public.chat_sessions (
  id bigint generated by default as identity primary key,

  owner_id uuid not null references auth.users(id) on delete cascade,

  title text not null default 'New chat',

  created_at timestamptz not null default now(),
  updated_at timestamptz not null default now()
);

create index if not exists chat_sessions_owner_id_idx on public.chat_sessions(owner_id);

comment on table public.chat_sessions is
'Chat-Konversationen pro User. Enthält viele Messages.';

drop trigger if exists trg_chat_sessions_set_updated_at on public.chat_sessions;
create trigger trg_chat_sessions_set_updated_at
before update on public.chat_sessions
for each row execute function public.set_updated_at();


-- ============================================================
-- 6) MESSAGES
-- ============================================================
-- owner_id bleibt bewusst: Multi-tenant Filter, auch für Assistant Messages.
-- role: user|assistant
-- Optional: metadata jsonb (z.B. tool calls, model, tokens)

create table if not exists public.messages (
  id bigint generated by default as identity primary key,

  chat_id bigint not null references public.chat_sessions(id) on delete cascade,

  owner_id uuid not null references auth.users(id) on delete cascade,

  role text not null check (role in ('user', 'assistant')),

  content text not null,

  -- optional: z.B. model, token_usage, citations, tool_calls
  metadata jsonb,

  created_at timestamptz not null default now()
);

create index if not exists messages_chat_id_idx on public.messages(chat_id);
create index if not exists messages_owner_id_idx on public.messages(owner_id);
create index if not exists messages_owner_chat_idx on public.messages(owner_id, chat_id, created_at);

comment on table public.messages is
'Chat-Nachrichten. role user/assistant; Assistant-Messages werden ebenfalls als owner_id=User gespeichert.';


-- ============================================================
-- 7) ROW LEVEL SECURITY (RLS)
-- ============================================================
-- Jeder User sieht und verändert ausschließlich seine Datensätze.

alter table public.profiles enable row level security;
alter table public.documents enable row level security;
alter table public.document_chunks enable row level security;
alter table public.chat_sessions enable row level security;
alter table public.messages enable row level security;

-- -------------------------
-- PROFILES POLICIES
-- -------------------------

create policy "profiles_select_own"
on public.profiles
for select
using (id = auth.uid());
comment on policy "profiles_select_own" on public.profiles is
'Erlaubt SELECT nur auf dem eigenen Profile-Datensatz (id == auth.uid()).';

create policy "profiles_insert_own"
on public.profiles
for insert
with check (id = auth.uid());
comment on policy "profiles_insert_own" on public.profiles is
'Erlaubt INSERT nur, wenn id == auth.uid() (kein Anlegen fremder Profile).';

create policy "profiles_update_own"
on public.profiles
for update
using (id = auth.uid())
with check (id = auth.uid());
comment on policy "profiles_update_own" on public.profiles is
'Erlaubt UPDATE nur auf eigenen Datensatz und verhindert Umschreiben der id.';

-- (Optional) Delete: meist nicht nötig, weil auth.users cascade löscht.
-- create policy "profiles_delete_own" ...


-- -------------------------
-- DOCUMENTS POLICIES
-- -------------------------

create policy "documents_crud_own"
on public.documents
for all
using (owner_id = auth.uid())
with check (owner_id = auth.uid());
comment on policy "documents_crud_own" on public.documents is
'Erlaubt CRUD nur für Dokumente mit owner_id == auth.uid().';

-- -------------------------
-- DOCUMENT_CHUNKS POLICIES
-- -------------------------

create policy "document_chunks_crud_own"
on public.document_chunks
for all
using (owner_id = auth.uid())
with check (owner_id = auth.uid());
comment on policy "document_chunks_crud_own" on public.document_chunks is
'Erlaubt CRUD nur für Chunks mit owner_id == auth.uid().';

-- -------------------------
-- CHAT_SESSIONS POLICIES
-- -------------------------

create policy "chat_sessions_crud_own"
on public.chat_sessions
for all
using (owner_id = auth.uid())
with check (owner_id = auth.uid());
comment on policy "chat_sessions_crud_own" on public.chat_sessions is
'Erlaubt CRUD nur für Chats mit owner_id == auth.uid().';

-- -------------------------
-- MESSAGES POLICIES
-- -------------------------

create policy "messages_crud_own"
on public.messages
for all
using (owner_id = auth.uid())
with check (owner_id = auth.uid());
comment on policy "messages_crud_own" on public.messages is
'Erlaubt CRUD nur für Messages mit owner_id == auth.uid().';


-- ============================================================
-- 8) RETRIEVAL FUNCTION (OPTIONAL, ABER PRAKTISCH)
-- ============================================================
-- Warum?
-- - Du kapselst Similarity Search serverseitig.
-- - Du kannst direkt owner_id filtern (RLS plus zusätzlicher Filter).
-- - Dein Next.js Backend ruft einfach RPC auf.
--
-- WICHTIG:
-- - security invoker (default) ist gut: RLS bleibt aktiv.
-- - Du kannst optional nach document_id filtern oder min_similarity ergänzen.

create or replace function public.match_chunks(
  query_embedding vector(1536),
  match_count int default 5
)
returns table (
  chunk_id bigint,
  document_id bigint,
  chunk_index int,
  content text,
  similarity float
)
language sql
stable
as $$
  select
    dc.id as chunk_id,
    dc.document_id,
    dc.chunk_index,
    dc.content,
    1 - (dc.embedding <=> query_embedding) as similarity
  from public.document_chunks dc
  where dc.owner_id = auth.uid()
  order by dc.embedding <=> query_embedding
  limit match_count;
$$;

comment on function public.match_chunks(vector, int) is
'Rückgabe der ähnlichsten Chunks (Cosine) für den aktuellen User (auth.uid()). Praktisch als RPC für RAG Retrieval.';


-- ============================================================
-- 9) AUTO-CREATE PROFILE ON SIGNUP (NICHT ZWINGEND)
-- ============================================================
-- Legt beim Anlegen eines Users automatisch einen zugehörigen Profile-Datensatz mit derselben UUID an, ohne Upserts im App-Code und ohne das Risiko fehlender Profile.
-- Der Trigger läuft bei jedem Insert in auth.users, unabhängig vom Auth-Flow (Email/Password, OAuth, Magic Link).
-- Die Funktion läuft mit den Rechten des Erstellers (security definer), nicht des aufrufenden Users, was nötig ist, um RLS zu umgehen und in profiles schreiben zu dürfen.

create or replace function public.handle_new_user()
returns trigger
language plpgsql
security definer
set search_path = public
as $$
begin
  insert into public.profiles (id)
  values (new.id)
  on conflict (id) do nothing;

  return new;
end;
$$;

-- WICHTIG: Ausführungsrechte hart runterdrehen
revoke all on function public.handle_new_user() from public;
revoke all on function public.handle_new_user() from anon;
revoke all on function public.handle_new_user() from authenticated;

-- Nur die Auth-Admin-Rolle darf ausführen
grant execute on function public.handle_new_user() to supabase_auth_admin;

drop trigger if exists on_auth_user_created on auth.users;
create trigger on_auth_user_created
after insert on auth.users
for each row execute function public.handle_new_user();


-- ============================================================
-- 10) POST-SETUP HINWEISE (keine SQL-Statements)
-- ============================================================
-- - Nach größeren Chunk-Imports: analyze public.document_chunks;
-- - Für PDF später: Upload in Storage -> documents.storage_path + document_type='pdf'
--   dann Parser/Extractor im Backend (oder Edge Function) -> raw_text + chunks.
-- ============================================================
